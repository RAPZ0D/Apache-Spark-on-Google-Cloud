{"cells": [{"cell_type": "markdown", "id": "b00eda28-fc7c-4c2e-9bae-b9b559b0552b", "metadata": {}, "source": "In this assignment I have loaded my dataset which is stored in my Google Bucket and from there I have actually used python transfer the data to my schema in Google BigQuery and here I load the dataset using Python "}, {"cell_type": "markdown", "id": "a89e7aa8-5102-4cfd-82fd-f9df92cb42d2", "metadata": {}, "source": "### Remember that all the data_uri and your bucket name project name and schema name might be different adapt to it accordingly"}, {"cell_type": "markdown", "id": "9d33d678-6988-45fe-8f80-aa1ee5346eb4", "metadata": {}, "source": "Remember you can load the data directly into the bucket as well but this assignment shows you how you can do it in Python and using your Dataproc Cluster "}, {"cell_type": "code", "execution_count": 1, "id": "3eb5b22d-7cd6-47f9-8c30-dd000552b9bf", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 2, "id": "1f2c582f-f223-41be-9bc9-c5c9f8d9731c", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/03/28 22:40:56 INFO SparkEnv: Registering MapOutputTracker\n24/03/28 22:40:56 INFO SparkEnv: Registering BlockManagerMaster\n24/03/28 22:40:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/03/28 22:40:56 INFO SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "spark = SparkSession.builder.appName(\"car_sales\").getOrCreate()"}, {"cell_type": "markdown", "id": "22f2959a-9a38-4d15-9871-487e3b00b9e3", "metadata": {}, "source": "The Dataset is the Car Sales in Canada"}, {"cell_type": "code", "execution_count": 7, "id": "86e0c475-0ca9-4484-ba7f-f35c9ff3b69f", "metadata": {"tags": []}, "outputs": [], "source": "data_uri= \"gs://mynewbucket-jm/Canadasalesdata.csv\""}, {"cell_type": "code", "execution_count": 8, "id": "6ba8eba7-4f30-40ae-97e1-d1b4a70f5189", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.read.csv(data_uri, header=True, inferSchema=True)\n"}, {"cell_type": "code", "execution_count": 9, "id": "f3ebb0ad-fe8b-4cc7-9869-dabb4feeee50", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- Model: string (nullable = true)\n |-- Jan: integer (nullable = true)\n |-- Feb: integer (nullable = true)\n |-- Mar: integer (nullable = true)\n |-- Apr: integer (nullable = true)\n |-- May: integer (nullable = true)\n |-- Jun: integer (nullable = true)\n |-- Jul: integer (nullable = true)\n |-- Aug: integer (nullable = true)\n |-- Sep: integer (nullable = true)\n |-- Oct: integer (nullable = true)\n |-- Nov: integer (nullable = true)\n |-- Dec: integer (nullable = true)\n |-- Sumofsales: integer (nullable = true)\n |-- Category: string (nullable = true)\n |-- Year: integer (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 10, "id": "26a72ac1-8aed-4253-84c9-59ca28e1f334", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+---+---+---+---+---+---+---+---+---+---+---+---+----------+--------+----+\n|    Model|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|Sumofsales|Category|Year|\n+---------+---+---+---+---+---+---+---+---+---+---+---+---+----------+--------+----+\n|Acura MDX| 93|389|782|611|550|501|  0|  0|  0|  0|  0|  0|      2926|     MLS|2021|\n|  Audi Q7|210|210|236|303|292|303|  0|  0|  0|  0|  0|  0|      1554|     MLS|2021|\n|  Audi Q8|130|130|146|211|203|211|  0|  0|  0|  0|  0|  0|      1031|     MLS|2021|\n|   BMW X5|323|323|364|518|498|518|  0|  0|  0|  0|  0|  0|      2544|     MLS|2021|\n|   BMW X6| 72| 72| 81|113|108|113|  0|  0|  0|  0|  0|  0|       559|     MLS|2021|\n+---------+---+---+---+---+---+---+---+---+---+---+---+---+----------+--------+----+\nonly showing top 5 rows\n\n"}], "source": "df.show(5)"}, {"cell_type": "markdown", "id": "f13d8765-493a-4f80-8fed-1afdec7a852f", "metadata": {}, "source": "Now i wanted to write this data into my Google Big Query where i already created my schema called Car Sales "}, {"cell_type": "code", "execution_count": 13, "id": "88238997-ad4e-4a5b-82e1-70632b2f80c6", "metadata": {"tags": []}, "outputs": [], "source": "project_id = \"spark3-418513\"\ndataset_id = \"carsales\"\ntable_id = \"canadacarsales\"\ntemporary_gcs_bucket = \"mynewbucket-jm\""}, {"cell_type": "code", "execution_count": 14, "id": "8411532b-709f-4e8c-a1d3-b14a5b3cc98b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\", f\"{project_id}.{dataset_id}.{table_id}\") \\\n  .option(\"temporaryGcsBucket\", temporary_gcs_bucket) \\\n  .save()"}, {"cell_type": "markdown", "id": "91040098-bb12-4d89-9aba-5342c6c0f709", "metadata": {}, "source": "The code below will take you data df and create a folder in your Google Bucket and save the data there incase you perfrom any new transformations and want to save the new dataset"}, {"cell_type": "code", "execution_count": 19, "id": "7ca91144-ffdb-470f-82b7-d0e4047ff28e", "metadata": {"tags": []}, "outputs": [], "source": "temporary_gcs_bucket = \"mynewbucket-jm\"\nfolder_name = \"test\"\noutput_path = f\"gs://{temporary_gcs_bucket}/{folder_name}\""}, {"cell_type": "code", "execution_count": 20, "id": "c9ae0f95-5768-4920-a1ab-40a4cde8ebd3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df.write \\\n  .format(\"csv\") \\\n  .option(\"header\", \"true\") \\\n  .mode(\"overwrite\") \\\n  .save(output_path)"}, {"cell_type": "code", "execution_count": null, "id": "b28646d2-ca32-4e73-8cbe-4d6a5b301375", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}